{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alphadev3296/deep-learning-practice/blob/main/Chapter-03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hyperthesis = x_train * W + b\n",
        "  cost = torch.mean((hyperthesis - y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} W:{W.item():.3f}, b:{b.item():.3f} Cost: {cost.item():.6f}\")"
      ],
      "metadata": {
        "id": "xcdBuJT458AD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd3934a-b04f-4461-d50d-caecd0b843f6",
        "collapsed": true
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 W:0.187, b:0.080 Cost: 18.666666\n",
            "Epoch  100/2000 W:1.746, b:0.578 Cost: 0.048171\n",
            "Epoch  200/2000 W:1.800, b:0.454 Cost: 0.029767\n",
            "Epoch  300/2000 W:1.843, b:0.357 Cost: 0.018394\n",
            "Epoch  400/2000 W:1.876, b:0.281 Cost: 0.011366\n",
            "Epoch  500/2000 W:1.903, b:0.221 Cost: 0.007024\n",
            "Epoch  600/2000 W:1.924, b:0.174 Cost: 0.004340\n",
            "Epoch  700/2000 W:1.940, b:0.136 Cost: 0.002682\n",
            "Epoch  800/2000 W:1.953, b:0.107 Cost: 0.001657\n",
            "Epoch  900/2000 W:1.963, b:0.084 Cost: 0.001024\n",
            "Epoch 1000/2000 W:1.971, b:0.066 Cost: 0.000633\n",
            "Epoch 1100/2000 W:1.977, b:0.052 Cost: 0.000391\n",
            "Epoch 1200/2000 W:1.982, b:0.041 Cost: 0.000242\n",
            "Epoch 1300/2000 W:1.986, b:0.032 Cost: 0.000149\n",
            "Epoch 1400/2000 W:1.989, b:0.025 Cost: 0.000092\n",
            "Epoch 1500/2000 W:1.991, b:0.020 Cost: 0.000057\n",
            "Epoch 1600/2000 W:1.993, b:0.016 Cost: 0.000035\n",
            "Epoch 1700/2000 W:1.995, b:0.012 Cost: 0.000022\n",
            "Epoch 1800/2000 W:1.996, b:0.010 Cost: 0.000013\n",
            "Epoch 1900/2000 W:1.997, b:0.008 Cost: 0.000008\n",
            "Epoch 2000/2000 W:1.997, b:0.006 Cost: 0.000005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multivariable Linear Regression\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 10000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hyperthesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
        "\n",
        "  cost = torch.mean((hyperthesis - y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 1000 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} w1: {w1.item():.3f} w2: {w2.item():.3f} w3: {w3.item():.3f} b: {b.item():.3f} Cost: {cost.item():.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tQBlAGr-MDqn",
        "outputId": "c3cddfb0-ff24-4c5f-b76b-6b24717ea084"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/10000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
            "Epoch 1000/10000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079390\n",
            "Epoch 2000/10000 w1: 0.757 w2: 0.571 w3: 0.682 b: 0.011 Cost: 0.754379\n",
            "Epoch 3000/10000 w1: 0.788 w2: 0.541 w3: 0.682 b: 0.012 Cost: 0.562653\n",
            "Epoch 4000/10000 w1: 0.812 w2: 0.517 w3: 0.681 b: 0.013 Cost: 0.448557\n",
            "Epoch 5000/10000 w1: 0.832 w2: 0.500 w3: 0.678 b: 0.014 Cost: 0.379739\n",
            "Epoch 6000/10000 w1: 0.848 w2: 0.488 w3: 0.675 b: 0.015 Cost: 0.337360\n",
            "Epoch 7000/10000 w1: 0.861 w2: 0.478 w3: 0.671 b: 0.016 Cost: 0.310474\n",
            "Epoch 8000/10000 w1: 0.871 w2: 0.472 w3: 0.667 b: 0.018 Cost: 0.292709\n",
            "Epoch 9000/10000 w1: 0.880 w2: 0.467 w3: 0.663 b: 0.019 Cost: 0.280348\n",
            "Epoch 10000/10000 w1: 0.888 w2: 0.464 w3: 0.658 b: 0.020 Cost: 0.271223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multivariable Linear Regresion with Matric\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "w = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([w, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 10000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hyperthesis = x_train.matmul(w) + b\n",
        "\n",
        "  cost = torch.mean((hyperthesis - y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 1000 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} hypothesis: {hyperthesis.squeeze().detach()} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(f\"w: {w.squeeze().detach()}, b: {b.item()}\")\n",
        "print(x_train.matmul(w) + b)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9dpCTcQ8M3e4",
        "outputId": "f17b75a4-0beb-4311-abab-11ffc81d9eb1"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/10000 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch 1000/10000 hypothesis: tensor([152.4312, 183.9319, 180.8577, 196.9723, 140.4543]) Cost: 1.079390\n",
            "Epoch 2000/10000 hypothesis: tensor([152.1425, 184.1316, 180.7716, 196.8914, 140.7322]) Cost: 0.754379\n",
            "Epoch 3000/10000 hypothesis: tensor([151.9242, 184.2831, 180.7070, 196.8267, 140.9463]) Cost: 0.562653\n",
            "Epoch 4000/10000 hypothesis: tensor([151.7595, 184.3978, 180.6588, 196.7742, 141.1117]) Cost: 0.448561\n",
            "Epoch 5000/10000 hypothesis: tensor([151.6356, 184.4845, 180.6230, 196.7311, 141.2401]) Cost: 0.379734\n",
            "Epoch 6000/10000 hypothesis: tensor([151.5428, 184.5499, 180.5967, 196.6953, 141.3400]) Cost: 0.337358\n",
            "Epoch 7000/10000 hypothesis: tensor([151.4737, 184.5989, 180.5777, 196.6651, 141.4182]) Cost: 0.310486\n",
            "Epoch 8000/10000 hypothesis: tensor([151.4225, 184.6355, 180.5640, 196.6393, 141.4799]) Cost: 0.292713\n",
            "Epoch 9000/10000 hypothesis: tensor([151.3851, 184.6628, 180.5545, 196.6168, 141.5288]) Cost: 0.280343\n",
            "Epoch 10000/10000 hypothesis: tensor([151.3581, 184.6828, 180.5482, 196.5970, 141.5680]) Cost: 0.271225\n",
            "w: tensor([0.8881, 0.4642, 0.6582]), b: 0.019540702924132347\n",
            "tensor([[151.3581],\n",
            "        [184.6828],\n",
            "        [180.5482],\n",
            "        [196.5970],\n",
            "        [141.5681]], grad_fn=<AddBackward0>)\n",
            "tensor([[152.],\n",
            "        [185.],\n",
            "        [180.],\n",
            "        [196.],\n",
            "        [142.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regresion with Module\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "input_dim = 1\n",
        "output_dim = 1\n",
        "\n",
        "model = nn.Linear(input_dim, output_dim)\n",
        "print(list(model.parameters()))\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(list(model.parameters()))\n",
        "pred_y = model(x_train)\n",
        "print(pred_y)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "drg1ErJmPfGh",
        "outputId": "82ccd146-6ae2-44a4-f39d-22bdbc0cdbf9"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n",
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n",
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n",
            "tensor([[2.0008],\n",
            "        [4.0002],\n",
            "        [5.9995]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[2.],\n",
            "        [4.],\n",
            "        [6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multivariable Linear Regresion with Module\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "model = nn.Linear(3, 1)\n",
        "\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(list(model.parameters()))\n",
        "pred_y = model(x_train)\n",
        "print(pred_y)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_YNjSBvdQtGg",
        "outputId": "89805dee-6e41-4355-8462-687e8a31eb44"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 31667.597656\n",
            "Epoch  100/2000 Cost: 0.225993\n",
            "Epoch  200/2000 Cost: 0.223911\n",
            "Epoch  300/2000 Cost: 0.221941\n",
            "Epoch  400/2000 Cost: 0.220059\n",
            "Epoch  500/2000 Cost: 0.218271\n",
            "Epoch  600/2000 Cost: 0.216575\n",
            "Epoch  700/2000 Cost: 0.214950\n",
            "Epoch  800/2000 Cost: 0.213413\n",
            "Epoch  900/2000 Cost: 0.211952\n",
            "Epoch 1000/2000 Cost: 0.210560\n",
            "Epoch 1100/2000 Cost: 0.209232\n",
            "Epoch 1200/2000 Cost: 0.207967\n",
            "Epoch 1300/2000 Cost: 0.206761\n",
            "Epoch 1400/2000 Cost: 0.205619\n",
            "Epoch 1500/2000 Cost: 0.204522\n",
            "Epoch 1600/2000 Cost: 0.203484\n",
            "Epoch 1700/2000 Cost: 0.202485\n",
            "Epoch 1800/2000 Cost: 0.201542\n",
            "Epoch 1900/2000 Cost: 0.200635\n",
            "Epoch 2000/2000 Cost: 0.199769\n",
            "[Parameter containing:\n",
            "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2802], requires_grad=True)]\n",
            "tensor([[151.2305],\n",
            "        [184.8005],\n",
            "        [180.5203],\n",
            "        [196.3101],\n",
            "        [141.9926]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[152.],\n",
            "        [185.],\n",
            "        [180.],\n",
            "        [196.],\n",
            "        [142.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Liner Regresion with Class\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class LinearRegresionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(1, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "model = LinearRegresionModel()\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(list(model.parameters()))\n",
        "pred_y = model(x_train)\n",
        "print(pred_y)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QL89DQddSdCh",
        "outputId": "c2aafbd0-68bf-4cb9-9ee5-7d0846053aca"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n",
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n",
            "tensor([[2.0008],\n",
            "        [4.0002],\n",
            "        [5.9995]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[2.],\n",
            "        [4.],\n",
            "        [6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multivariable Linear Segression with Class\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "class MultivariableLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "model = MultivariableLinearRegressionModel()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(list(model.parameters()))\n",
        "pred_y = model(x_train)\n",
        "print(pred_y)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UY0QgXEqTunx",
        "outputId": "8200ab17-d66d-4ec1-d143-ef36f8f927ff"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 31667.597656\n",
            "Epoch  100/2000 Cost: 0.225993\n",
            "Epoch  200/2000 Cost: 0.223911\n",
            "Epoch  300/2000 Cost: 0.221941\n",
            "Epoch  400/2000 Cost: 0.220059\n",
            "Epoch  500/2000 Cost: 0.218271\n",
            "Epoch  600/2000 Cost: 0.216575\n",
            "Epoch  700/2000 Cost: 0.214950\n",
            "Epoch  800/2000 Cost: 0.213413\n",
            "Epoch  900/2000 Cost: 0.211952\n",
            "Epoch 1000/2000 Cost: 0.210560\n",
            "Epoch 1100/2000 Cost: 0.209232\n",
            "Epoch 1200/2000 Cost: 0.207967\n",
            "Epoch 1300/2000 Cost: 0.206761\n",
            "Epoch 1400/2000 Cost: 0.205619\n",
            "Epoch 1500/2000 Cost: 0.204522\n",
            "Epoch 1600/2000 Cost: 0.203484\n",
            "Epoch 1700/2000 Cost: 0.202485\n",
            "Epoch 1800/2000 Cost: 0.201542\n",
            "Epoch 1900/2000 Cost: 0.200635\n",
            "Epoch 2000/2000 Cost: 0.199769\n",
            "[Parameter containing:\n",
            "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2802], requires_grad=True)]\n",
            "tensor([[151.2305],\n",
            "        [184.8005],\n",
            "        [180.5203],\n",
            "        [196.3101],\n",
            "        [141.9926]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[152.],\n",
            "        [185.],\n",
            "        [180.],\n",
            "        [196.],\n",
            "        [142.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression with Minibatch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "dataset = TensorDataset(x_train, y_train)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "model = nn.Linear(3, 1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    x_train, y_train = samples\n",
        "    prediction = model(x_train)\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} Batch {batch_idx+1}/{len(dataloader)} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(list(model.parameters()))\n",
        "y_pred = model(x_train)\n",
        "print(y_pred)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S882AqidZ_ns",
        "outputId": "36293c4b-fef0-458f-f27f-4006b6320f2f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 23071.781250\n",
            "Epoch    0/20 Batch 2/3 Cost: 17581.359375\n",
            "Epoch    0/20 Batch 3/3 Cost: 3703.553467\n",
            "Epoch    1/20 Batch 1/3 Cost: 857.131836\n",
            "Epoch    1/20 Batch 2/3 Cost: 194.912628\n",
            "Epoch    1/20 Batch 3/3 Cost: 103.150658\n",
            "Epoch    2/20 Batch 1/3 Cost: 16.460945\n",
            "Epoch    2/20 Batch 2/3 Cost: 10.970690\n",
            "Epoch    2/20 Batch 3/3 Cost: 2.953053\n",
            "Epoch    3/20 Batch 1/3 Cost: 1.246350\n",
            "Epoch    3/20 Batch 2/3 Cost: 0.095024\n",
            "Epoch    3/20 Batch 3/3 Cost: 0.104377\n",
            "Epoch    4/20 Batch 1/3 Cost: 0.678422\n",
            "Epoch    4/20 Batch 2/3 Cost: 0.123370\n",
            "Epoch    4/20 Batch 3/3 Cost: 0.118080\n",
            "Epoch    5/20 Batch 1/3 Cost: 0.094797\n",
            "Epoch    5/20 Batch 2/3 Cost: 0.531496\n",
            "Epoch    5/20 Batch 3/3 Cost: 0.011198\n",
            "Epoch    6/20 Batch 1/3 Cost: 0.219984\n",
            "Epoch    6/20 Batch 2/3 Cost: 0.042412\n",
            "Epoch    6/20 Batch 3/3 Cost: 0.917457\n",
            "Epoch    7/20 Batch 1/3 Cost: 0.213805\n",
            "Epoch    7/20 Batch 2/3 Cost: 0.640249\n",
            "Epoch    7/20 Batch 3/3 Cost: 0.005267\n",
            "Epoch    8/20 Batch 1/3 Cost: 0.454904\n",
            "Epoch    8/20 Batch 2/3 Cost: 0.011374\n",
            "Epoch    8/20 Batch 3/3 Cost: 0.298689\n",
            "Epoch    9/20 Batch 1/3 Cost: 0.560365\n",
            "Epoch    9/20 Batch 2/3 Cost: 0.011228\n",
            "Epoch    9/20 Batch 3/3 Cost: 0.244160\n",
            "Epoch   10/20 Batch 1/3 Cost: 0.613739\n",
            "Epoch   10/20 Batch 2/3 Cost: 0.024911\n",
            "Epoch   10/20 Batch 3/3 Cost: 0.066365\n",
            "Epoch   11/20 Batch 1/3 Cost: 0.116626\n",
            "Epoch   11/20 Batch 2/3 Cost: 0.045004\n",
            "Epoch   11/20 Batch 3/3 Cost: 0.958777\n",
            "Epoch   12/20 Batch 1/3 Cost: 0.234996\n",
            "Epoch   12/20 Batch 2/3 Cost: 0.154496\n",
            "Epoch   12/20 Batch 3/3 Cost: 0.861088\n",
            "Epoch   13/20 Batch 1/3 Cost: 0.398488\n",
            "Epoch   13/20 Batch 2/3 Cost: 0.304441\n",
            "Epoch   13/20 Batch 3/3 Cost: 0.015352\n",
            "Epoch   14/20 Batch 1/3 Cost: 0.050674\n",
            "Epoch   14/20 Batch 2/3 Cost: 0.482778\n",
            "Epoch   14/20 Batch 3/3 Cost: 0.414241\n",
            "Epoch   15/20 Batch 1/3 Cost: 0.513222\n",
            "Epoch   15/20 Batch 2/3 Cost: 0.068332\n",
            "Epoch   15/20 Batch 3/3 Cost: 0.215187\n",
            "Epoch   16/20 Batch 1/3 Cost: 0.069614\n",
            "Epoch   16/20 Batch 2/3 Cost: 0.052825\n",
            "Epoch   16/20 Batch 3/3 Cost: 1.164131\n",
            "Epoch   17/20 Batch 1/3 Cost: 0.034010\n",
            "Epoch   17/20 Batch 2/3 Cost: 0.486735\n",
            "Epoch   17/20 Batch 3/3 Cost: 0.209226\n",
            "Epoch   18/20 Batch 1/3 Cost: 0.024246\n",
            "Epoch   18/20 Batch 2/3 Cost: 0.129105\n",
            "Epoch   18/20 Batch 3/3 Cost: 1.134490\n",
            "Epoch   19/20 Batch 1/3 Cost: 0.490361\n",
            "Epoch   19/20 Batch 2/3 Cost: 0.154791\n",
            "Epoch   19/20 Batch 3/3 Cost: 0.011797\n",
            "Epoch   20/20 Batch 1/3 Cost: 0.408733\n",
            "Epoch   20/20 Batch 2/3 Cost: 0.194442\n",
            "Epoch   20/20 Batch 3/3 Cost: 0.004536\n",
            "[Parameter containing:\n",
            "tensor([[0.9867, 0.4365, 0.5847]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2792], requires_grad=True)]\n",
            "tensor([[142.0477]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[142.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression with Custom dataset\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.x_data = [[73, 80, 75],\n",
        "                  [93, 88, 93],\n",
        "                  [89, 91, 90],\n",
        "                  [96, 98, 100],\n",
        "                  [73, 66, 70]]\n",
        "    self.y_data = [[152], [185], [180], [196], [142]]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "    return x, y\n",
        "\n",
        "dataset = CustomDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "model = nn.Linear(3, 1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    x_train, y_train = samples\n",
        "    prediction = model(x_train)\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} Batch {batch_idx+1}/{len(dataloader)} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(list(model.parameters()))\n",
        "y_pred = model(x_train)\n",
        "print(y_pred)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b3Obg0J7cpXl",
        "outputId": "ca82f05f-2506-486b-90cb-3cbf7f9e5826"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 23071.781250\n",
            "Epoch    0/20 Batch 2/3 Cost: 17581.359375\n",
            "Epoch    0/20 Batch 3/3 Cost: 3703.553467\n",
            "Epoch    1/20 Batch 1/3 Cost: 857.131836\n",
            "Epoch    1/20 Batch 2/3 Cost: 194.912628\n",
            "Epoch    1/20 Batch 3/3 Cost: 103.150658\n",
            "Epoch    2/20 Batch 1/3 Cost: 16.460945\n",
            "Epoch    2/20 Batch 2/3 Cost: 10.970690\n",
            "Epoch    2/20 Batch 3/3 Cost: 2.953053\n",
            "Epoch    3/20 Batch 1/3 Cost: 1.246350\n",
            "Epoch    3/20 Batch 2/3 Cost: 0.095024\n",
            "Epoch    3/20 Batch 3/3 Cost: 0.104377\n",
            "Epoch    4/20 Batch 1/3 Cost: 0.678422\n",
            "Epoch    4/20 Batch 2/3 Cost: 0.123370\n",
            "Epoch    4/20 Batch 3/3 Cost: 0.118080\n",
            "Epoch    5/20 Batch 1/3 Cost: 0.094797\n",
            "Epoch    5/20 Batch 2/3 Cost: 0.531496\n",
            "Epoch    5/20 Batch 3/3 Cost: 0.011198\n",
            "Epoch    6/20 Batch 1/3 Cost: 0.219984\n",
            "Epoch    6/20 Batch 2/3 Cost: 0.042412\n",
            "Epoch    6/20 Batch 3/3 Cost: 0.917457\n",
            "Epoch    7/20 Batch 1/3 Cost: 0.213805\n",
            "Epoch    7/20 Batch 2/3 Cost: 0.640249\n",
            "Epoch    7/20 Batch 3/3 Cost: 0.005267\n",
            "Epoch    8/20 Batch 1/3 Cost: 0.454904\n",
            "Epoch    8/20 Batch 2/3 Cost: 0.011374\n",
            "Epoch    8/20 Batch 3/3 Cost: 0.298689\n",
            "Epoch    9/20 Batch 1/3 Cost: 0.560365\n",
            "Epoch    9/20 Batch 2/3 Cost: 0.011228\n",
            "Epoch    9/20 Batch 3/3 Cost: 0.244160\n",
            "Epoch   10/20 Batch 1/3 Cost: 0.613739\n",
            "Epoch   10/20 Batch 2/3 Cost: 0.024911\n",
            "Epoch   10/20 Batch 3/3 Cost: 0.066365\n",
            "Epoch   11/20 Batch 1/3 Cost: 0.116626\n",
            "Epoch   11/20 Batch 2/3 Cost: 0.045004\n",
            "Epoch   11/20 Batch 3/3 Cost: 0.958777\n",
            "Epoch   12/20 Batch 1/3 Cost: 0.234996\n",
            "Epoch   12/20 Batch 2/3 Cost: 0.154496\n",
            "Epoch   12/20 Batch 3/3 Cost: 0.861088\n",
            "Epoch   13/20 Batch 1/3 Cost: 0.398488\n",
            "Epoch   13/20 Batch 2/3 Cost: 0.304441\n",
            "Epoch   13/20 Batch 3/3 Cost: 0.015352\n",
            "Epoch   14/20 Batch 1/3 Cost: 0.050674\n",
            "Epoch   14/20 Batch 2/3 Cost: 0.482778\n",
            "Epoch   14/20 Batch 3/3 Cost: 0.414241\n",
            "Epoch   15/20 Batch 1/3 Cost: 0.513222\n",
            "Epoch   15/20 Batch 2/3 Cost: 0.068332\n",
            "Epoch   15/20 Batch 3/3 Cost: 0.215187\n",
            "Epoch   16/20 Batch 1/3 Cost: 0.069614\n",
            "Epoch   16/20 Batch 2/3 Cost: 0.052825\n",
            "Epoch   16/20 Batch 3/3 Cost: 1.164131\n",
            "Epoch   17/20 Batch 1/3 Cost: 0.034010\n",
            "Epoch   17/20 Batch 2/3 Cost: 0.486735\n",
            "Epoch   17/20 Batch 3/3 Cost: 0.209226\n",
            "Epoch   18/20 Batch 1/3 Cost: 0.024246\n",
            "Epoch   18/20 Batch 2/3 Cost: 0.129105\n",
            "Epoch   18/20 Batch 3/3 Cost: 1.134490\n",
            "Epoch   19/20 Batch 1/3 Cost: 0.490361\n",
            "Epoch   19/20 Batch 2/3 Cost: 0.154791\n",
            "Epoch   19/20 Batch 3/3 Cost: 0.011797\n",
            "Epoch   20/20 Batch 1/3 Cost: 0.408733\n",
            "Epoch   20/20 Batch 2/3 Cost: 0.194442\n",
            "Epoch   20/20 Batch 3/3 Cost: 0.004536\n",
            "[Parameter containing:\n",
            "tensor([[0.9867, 0.4365, 0.5847]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2792], requires_grad=True)]\n",
            "tensor([[142.0477]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[142.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Revision vector and matrix operations\n",
        "import numpy as np\n",
        "\n",
        "d = np.array(5)\n",
        "print(f\"value: {d}\")\n",
        "print(f\"dimension: {d.ndim}\")\n",
        "print(f\"shape: {d.shape}\")\n",
        "\n",
        "d = np.array([1, 2, 3, 4])\n",
        "print(f\"value: {d}\")\n",
        "print(f\"dimension: {d.ndim}\")\n",
        "print(f\"shape: {d.shape}\")\n",
        "\n",
        "d = np.array([[1, 2, 3, 4],\n",
        "              [5, 6, 7, 8],\n",
        "              [9, 10, 11, 12]])\n",
        "print(f\"value: {d}\")\n",
        "print(f\"dimension: {d.ndim}\")\n",
        "print(f\"shape: {d.shape}\")\n",
        "\n",
        "d = np.array([\n",
        "    [[1, 2, 3, 4, 5],\n",
        "      [6, 7, 8, 9, 10],\n",
        "      [10, 11, 12, 13, 14]],\n",
        "    [[15, 16, 17, 18, 19],\n",
        "      [19, 20, 21, 22, 23],\n",
        "      [23, 24 ,25, 26, 27]]\n",
        "])\n",
        "print(f\"value: {d}\")\n",
        "print(f\"dimension: {d.ndim}\")\n",
        "print(f\"shape: {d.shape}\")\n",
        "\n",
        "A = np.array([1, 2, 3])\n",
        "B = np.array([4, 5, 6])\n",
        "print(f\"A+B: {A+B}\")\n",
        "print(f\"A-B: {A-B}\")\n",
        "print(f\"A*B: {A*B}\")\n",
        "print(f\"A.B: {np.dot(A,B)}\")\n",
        "\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([[5, 6], [7, 8]])\n",
        "print(f\"AxB: {np.matmul(A,B)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knkUMcQUe2aS",
        "outputId": "2fb73791-4c5c-409e-b9b2-37f03aa522ff"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value: 5\n",
            "dimension: 0\n",
            "shape: ()\n",
            "value: [1 2 3 4]\n",
            "dimension: 1\n",
            "shape: (4,)\n",
            "value: [[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]]\n",
            "dimension: 2\n",
            "shape: (3, 4)\n",
            "value: [[[ 1  2  3  4  5]\n",
            "  [ 6  7  8  9 10]\n",
            "  [10 11 12 13 14]]\n",
            "\n",
            " [[15 16 17 18 19]\n",
            "  [19 20 21 22 23]\n",
            "  [23 24 25 26 27]]]\n",
            "dimension: 3\n",
            "shape: (2, 3, 5)\n",
            "A+B: [5 7 9]\n",
            "A-B: [-3 -3 -3]\n",
            "A*B: [ 4 10 18]\n",
            "A.B: 32\n",
            "AxB: [[19 22]\n",
            " [43 50]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}