{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alphadev3296/deep-learning-practice-03/blob/main/Deep_Learning_Practice-03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Linear Regression\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hyperthesis = x_train * W + b\n",
        "  cost = torch.mean((hyperthesis - y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} W:{W.item():.3f}, b:{b.item():.3f} Cost: {cost.item():.6f}\")"
      ],
      "metadata": {
        "id": "xcdBuJT458AD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd3934a-b04f-4461-d50d-caecd0b843f6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 W:0.187, b:0.080 Cost: 18.666666\n",
            "Epoch  100/2000 W:1.746, b:0.578 Cost: 0.048171\n",
            "Epoch  200/2000 W:1.800, b:0.454 Cost: 0.029767\n",
            "Epoch  300/2000 W:1.843, b:0.357 Cost: 0.018394\n",
            "Epoch  400/2000 W:1.876, b:0.281 Cost: 0.011366\n",
            "Epoch  500/2000 W:1.903, b:0.221 Cost: 0.007024\n",
            "Epoch  600/2000 W:1.924, b:0.174 Cost: 0.004340\n",
            "Epoch  700/2000 W:1.940, b:0.136 Cost: 0.002682\n",
            "Epoch  800/2000 W:1.953, b:0.107 Cost: 0.001657\n",
            "Epoch  900/2000 W:1.963, b:0.084 Cost: 0.001024\n",
            "Epoch 1000/2000 W:1.971, b:0.066 Cost: 0.000633\n",
            "Epoch 1100/2000 W:1.977, b:0.052 Cost: 0.000391\n",
            "Epoch 1200/2000 W:1.982, b:0.041 Cost: 0.000242\n",
            "Epoch 1300/2000 W:1.986, b:0.032 Cost: 0.000149\n",
            "Epoch 1400/2000 W:1.989, b:0.025 Cost: 0.000092\n",
            "Epoch 1500/2000 W:1.991, b:0.020 Cost: 0.000057\n",
            "Epoch 1600/2000 W:1.993, b:0.016 Cost: 0.000035\n",
            "Epoch 1700/2000 W:1.995, b:0.012 Cost: 0.000022\n",
            "Epoch 1800/2000 W:1.996, b:0.010 Cost: 0.000013\n",
            "Epoch 1900/2000 W:1.997, b:0.008 Cost: 0.000008\n",
            "Epoch 2000/2000 W:1.997, b:0.006 Cost: 0.000005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Multivariable Linear Regression - 1\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 10000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hyperthesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
        "\n",
        "  cost = torch.mean((hyperthesis - y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 1000 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} w1: {w1.item():.3f} w2: {w2.item():.3f} w3: {w3.item():.3f} b: {b.item():.3f} Cost: {cost.item():.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQBlAGr-MDqn",
        "outputId": "c3cddfb0-ff24-4c5f-b76b-6b24717ea084"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/10000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
            "Epoch 1000/10000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079390\n",
            "Epoch 2000/10000 w1: 0.757 w2: 0.571 w3: 0.682 b: 0.011 Cost: 0.754379\n",
            "Epoch 3000/10000 w1: 0.788 w2: 0.541 w3: 0.682 b: 0.012 Cost: 0.562653\n",
            "Epoch 4000/10000 w1: 0.812 w2: 0.517 w3: 0.681 b: 0.013 Cost: 0.448557\n",
            "Epoch 5000/10000 w1: 0.832 w2: 0.500 w3: 0.678 b: 0.014 Cost: 0.379739\n",
            "Epoch 6000/10000 w1: 0.848 w2: 0.488 w3: 0.675 b: 0.015 Cost: 0.337360\n",
            "Epoch 7000/10000 w1: 0.861 w2: 0.478 w3: 0.671 b: 0.016 Cost: 0.310474\n",
            "Epoch 8000/10000 w1: 0.871 w2: 0.472 w3: 0.667 b: 0.018 Cost: 0.292709\n",
            "Epoch 9000/10000 w1: 0.880 w2: 0.467 w3: 0.663 b: 0.019 Cost: 0.280348\n",
            "Epoch 10000/10000 w1: 0.888 w2: 0.464 w3: 0.658 b: 0.020 Cost: 0.271223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Multivariable Linear Regresion - 2\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "w = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([w, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 10000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hyperthesis = x_train.matmul(w) + b\n",
        "\n",
        "  cost = torch.mean((hyperthesis - y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 1000 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} hypothesis: {hyperthesis.squeeze().detach()} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(f\"w: {w.squeeze().detach()}, b: {b.item()}\")\n",
        "print(x_train.matmul(w) + b)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dpCTcQ8M3e4",
        "outputId": "f17b75a4-0beb-4311-abab-11ffc81d9eb1"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/10000 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch 1000/10000 hypothesis: tensor([152.4312, 183.9319, 180.8577, 196.9723, 140.4543]) Cost: 1.079390\n",
            "Epoch 2000/10000 hypothesis: tensor([152.1425, 184.1316, 180.7716, 196.8914, 140.7322]) Cost: 0.754379\n",
            "Epoch 3000/10000 hypothesis: tensor([151.9242, 184.2831, 180.7070, 196.8267, 140.9463]) Cost: 0.562653\n",
            "Epoch 4000/10000 hypothesis: tensor([151.7595, 184.3978, 180.6588, 196.7742, 141.1117]) Cost: 0.448561\n",
            "Epoch 5000/10000 hypothesis: tensor([151.6356, 184.4845, 180.6230, 196.7311, 141.2401]) Cost: 0.379734\n",
            "Epoch 6000/10000 hypothesis: tensor([151.5428, 184.5499, 180.5967, 196.6953, 141.3400]) Cost: 0.337358\n",
            "Epoch 7000/10000 hypothesis: tensor([151.4737, 184.5989, 180.5777, 196.6651, 141.4182]) Cost: 0.310486\n",
            "Epoch 8000/10000 hypothesis: tensor([151.4225, 184.6355, 180.5640, 196.6393, 141.4799]) Cost: 0.292713\n",
            "Epoch 9000/10000 hypothesis: tensor([151.3851, 184.6628, 180.5545, 196.6168, 141.5288]) Cost: 0.280343\n",
            "Epoch 10000/10000 hypothesis: tensor([151.3581, 184.6828, 180.5482, 196.5970, 141.5680]) Cost: 0.271225\n",
            "w: tensor([0.8881, 0.4642, 0.6582]), b: 0.019540702924132347\n",
            "tensor([[151.3581],\n",
            "        [184.6828],\n",
            "        [180.5482],\n",
            "        [196.5970],\n",
            "        [141.5681]], grad_fn=<AddBackward0>)\n",
            "tensor([[152.],\n",
            "        [185.],\n",
            "        [180.],\n",
            "        [196.],\n",
            "        [142.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Linear Regresion with Module\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "input_dim = 1\n",
        "output_dim = 1\n",
        "\n",
        "model = nn.Linear(input_dim, output_dim)\n",
        "print(list(model.parameters()))\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(list(model.parameters()))\n",
        "pred_y = model(x_train)\n",
        "print(pred_y)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drg1ErJmPfGh",
        "outputId": "82ccd146-6ae2-44a4-f39d-22bdbc0cdbf9"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n",
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n",
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n",
            "tensor([[2.0008],\n",
            "        [4.0002],\n",
            "        [5.9995]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[2.],\n",
            "        [4.],\n",
            "        [6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Multivariable Linear Regresion with Module\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "model = nn.Linear(3, 1)\n",
        "\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(list(model.parameters()))\n",
        "pred_y = model(x_train)\n",
        "print(pred_y)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YNjSBvdQtGg",
        "outputId": "89805dee-6e41-4355-8462-687e8a31eb44"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 31667.597656\n",
            "Epoch  100/2000 Cost: 0.225993\n",
            "Epoch  200/2000 Cost: 0.223911\n",
            "Epoch  300/2000 Cost: 0.221941\n",
            "Epoch  400/2000 Cost: 0.220059\n",
            "Epoch  500/2000 Cost: 0.218271\n",
            "Epoch  600/2000 Cost: 0.216575\n",
            "Epoch  700/2000 Cost: 0.214950\n",
            "Epoch  800/2000 Cost: 0.213413\n",
            "Epoch  900/2000 Cost: 0.211952\n",
            "Epoch 1000/2000 Cost: 0.210560\n",
            "Epoch 1100/2000 Cost: 0.209232\n",
            "Epoch 1200/2000 Cost: 0.207967\n",
            "Epoch 1300/2000 Cost: 0.206761\n",
            "Epoch 1400/2000 Cost: 0.205619\n",
            "Epoch 1500/2000 Cost: 0.204522\n",
            "Epoch 1600/2000 Cost: 0.203484\n",
            "Epoch 1700/2000 Cost: 0.202485\n",
            "Epoch 1800/2000 Cost: 0.201542\n",
            "Epoch 1900/2000 Cost: 0.200635\n",
            "Epoch 2000/2000 Cost: 0.199769\n",
            "[Parameter containing:\n",
            "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2802], requires_grad=True)]\n",
            "tensor([[151.2305],\n",
            "        [184.8005],\n",
            "        [180.5203],\n",
            "        [196.3101],\n",
            "        [141.9926]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[152.],\n",
            "        [185.],\n",
            "        [180.],\n",
            "        [196.],\n",
            "        [142.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Liner Regresion with Class\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class LinearRegresionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(1, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "model = LinearRegresionModel()\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(list(model.parameters()))\n",
        "pred_y = model(x_train)\n",
        "print(pred_y)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL89DQddSdCh",
        "outputId": "c2aafbd0-68bf-4cb9-9ee5-7d0846053aca"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n",
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n",
            "tensor([[2.0008],\n",
            "        [4.0002],\n",
            "        [5.9995]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[2.],\n",
            "        [4.],\n",
            "        [6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Multivariable Linear Segression with Class\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "class MultivariableLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "model = MultivariableLinearRegressionModel()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}\")\n",
        "\n",
        "print(list(model.parameters()))\n",
        "pred_y = model(x_train)\n",
        "print(pred_y)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY0QgXEqTunx",
        "outputId": "8200ab17-d66d-4ec1-d143-ef36f8f927ff"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 31667.597656\n",
            "Epoch  100/2000 Cost: 0.225993\n",
            "Epoch  200/2000 Cost: 0.223911\n",
            "Epoch  300/2000 Cost: 0.221941\n",
            "Epoch  400/2000 Cost: 0.220059\n",
            "Epoch  500/2000 Cost: 0.218271\n",
            "Epoch  600/2000 Cost: 0.216575\n",
            "Epoch  700/2000 Cost: 0.214950\n",
            "Epoch  800/2000 Cost: 0.213413\n",
            "Epoch  900/2000 Cost: 0.211952\n",
            "Epoch 1000/2000 Cost: 0.210560\n",
            "Epoch 1100/2000 Cost: 0.209232\n",
            "Epoch 1200/2000 Cost: 0.207967\n",
            "Epoch 1300/2000 Cost: 0.206761\n",
            "Epoch 1400/2000 Cost: 0.205619\n",
            "Epoch 1500/2000 Cost: 0.204522\n",
            "Epoch 1600/2000 Cost: 0.203484\n",
            "Epoch 1700/2000 Cost: 0.202485\n",
            "Epoch 1800/2000 Cost: 0.201542\n",
            "Epoch 1900/2000 Cost: 0.200635\n",
            "Epoch 2000/2000 Cost: 0.199769\n",
            "[Parameter containing:\n",
            "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2802], requires_grad=True)]\n",
            "tensor([[151.2305],\n",
            "        [184.8005],\n",
            "        [180.5203],\n",
            "        [196.3101],\n",
            "        [141.9926]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[152.],\n",
            "        [185.],\n",
            "        [180.],\n",
            "        [196.],\n",
            "        [142.]])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}